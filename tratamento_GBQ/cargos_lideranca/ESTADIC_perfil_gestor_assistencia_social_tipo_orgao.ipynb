{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "ZJPBBAq3Dk1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Google Cloud SDK components (typically run once per environment)\n",
        "# Note: These are shell commands, not Python code, hence the '!' prefix in Jupyter notebooks\n",
        "!pip install gcloud  # Installs the Google Cloud CLI tools\n",
        "!gcloud auth application-default login  # Sets up application default credentials for GCP access\n",
        "\n",
        "# Import required Python packages for data processing and Google Cloud operations\n",
        "import pandas as pd         # Primary data analysis library (DataFrames, Series)\n",
        "import numpy as np          # Numerical computing (arrays, math operations)\n",
        "import time                 # Time measurement and delays\n",
        "import os                   # Operating system interactions (files, paths)\n",
        "import pandas_gbq           # Pandas-BigQuery integration (direct DataFrame transfers)\n",
        "from google.cloud import bigquery  # Official BigQuery client library (detailed operations)\n",
        "import glob                 # File path pattern matching (finding files by patterns)\n",
        "import openpyxl             # Excel file reading/writing (.xlsx format support)\n",
        "import csv                  # CSV file reading/writing\n",
        "import re                   # Regular expressions (text pattern matching)"
      ],
      "metadata": {
        "id": "XPvF3bg5DrmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "ytJ4QruYDnzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from Excel file (Social Assistance sheet)\n",
        "df = pd.read_excel(\"Base_Estadic_2023(2).xlsx\", sheet_name='Assistência Social')\n",
        "\n",
        "# Select relevant columns and preview data\n",
        "df = df[['Sigla UF', 'Cod UF', 'Nome UF', 'EASS01', 'EASS03', 'EASS04', 'EASS05', 'EASS06']]\n",
        "df['ano'] = 2023  # Add year column\n",
        "\n",
        "# Rename columns for clarity\n",
        "df = df.rename(columns={\n",
        "    'Sigla UF': 'sigla_uf',\n",
        "    'Cod UF': 'cod_uf',\n",
        "    'Nome UF': 'uf',\n",
        "    'EASS01': 'caracterizacao_orgao_gestor',\n",
        "    'EASS03': 'genero',\n",
        "    'EASS04': 'idade',\n",
        "    'EASS05': 'cor_raca',\n",
        "    'EASS06': 'grau_instrucao'\n",
        "})\n",
        "\n",
        "# Clean and standardize data\n",
        "df['caracterizacao_orgao_gestor'] = df['caracterizacao_orgao_gestor'].str.title()\n",
        "df['cor_raca'] = np.where(df['cor_raca'] == 'Pardo', 'Parda', df['cor_raca'])\n",
        "\n",
        "# Handle missing/refused data\n",
        "for col in ['caracterizacao_orgao_gestor', 'genero', 'cor_raca', 'grau_instrucao']:\n",
        "    df[col] = np.where(df[col].isin(['Recusa', 'Não Informou', 'Não informou']),\n",
        "                     'Sem dados',\n",
        "                     df[col])\n",
        "\n",
        "# Convert age to numeric and handle missing values\n",
        "df['idade'] = np.where(df['idade'].isin(['Recusa', 'Não informou']), np.nan, df['idade'])\n",
        "df['idade'] = pd.to_numeric(df['idade'])\n",
        "\n",
        "# Create age groups\n",
        "limites = [18, 30, 50, 65, 100]\n",
        "categorias = ['Entre 18-29', 'Entre 30-49', 'Entre 50-64', 'Acima de 65']\n",
        "df['faixa_etaria'] = pd.cut(df['idade'], bins=limites, labels=categorias, right=False)\n",
        "\n",
        "# Select final columns\n",
        "df = df[['ano', 'sigla_uf', 'cod_uf', 'uf', 'caracterizacao_orgao_gestor',\n",
        "         'genero', 'faixa_etaria', 'cor_raca', 'grau_instrucao']]\n",
        "\n",
        "# Standardize education levels\n",
        "dict_esco = {\n",
        "    'Ensino superior completo': 'Até Ensino Superior Completo',\n",
        "    'Especialização': 'Até Pós Graduação ou Mestrado',\n",
        "    'Mestrado': 'Até Pós Graduação ou Mestrado',\n",
        "    'Doutorado': 'Até Doutorado'\n",
        "}\n",
        "df = df.replace({'grau_instrucao': dict_esco})\n",
        "\n",
        "# Preview final data\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "id": "JbokcQcgEgJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "Bk1FgF-6Dpjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the BigQuery table schema with field descriptions in Portuguese\n",
        "schema = [\n",
        "    bigquery.SchemaField('ano', 'INTEGER', description='Ano da apuração daquele dado'),\n",
        "    bigquery.SchemaField('sigla_uf', 'STRING', description='Sigla da UF'),\n",
        "    bigquery.SchemaField('cod_uf', 'INTEGER', description='Código do IBGE da UF'),\n",
        "    bigquery.SchemaField('uf', 'STRING', description='Nome da UF'),\n",
        "    bigquery.SchemaField('caracterizacao_orgao_gestor', 'STRING',\n",
        "                       description='Caracterização do órgão no qual o gestor está'),\n",
        "    bigquery.SchemaField('genero', 'STRING',\n",
        "                       description='Gênero autodeclarado ou não'),\n",
        "    bigquery.SchemaField('faixa_etaria', 'STRING',\n",
        "                       description='faixa etária da observação'),\n",
        "    bigquery.SchemaField('cor_raca', 'STRING',\n",
        "                       description='Raça/cor da pessoa observada'),\n",
        "    bigquery.SchemaField('grau_instrucao', 'STRING',\n",
        "                       description='Escolaridade da pessoa ou do vínculo observado com detalhamento na pós-graduação')\n",
        "]\n",
        "\n",
        "# Initialize BigQuery client connection\n",
        "# Using the specified project 'repositoriodedadosgpsp'\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create reference to target dataset 'cargos_lideranca'\n",
        "dataset_ref = client.dataset('cargos_lideranca')\n",
        "\n",
        "# Create reference to target table with standardized naming convention:\n",
        "# Format: SOURCE_descriptive_name_version (ESTADIC_perfil_gestor_assistencia_social_tipo_orgao_v4)\n",
        "table_ref = dataset_ref.table('ESTADIC_perfil_gestor_assistencia_social_tipo_orgao_v4')\n",
        "\n",
        "# Configure the load job with our schema definition\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Execute the load job to transfer DataFrame to BigQuery\n",
        "# Parameters:\n",
        "#   df - The pandas DataFrame containing our processed data\n",
        "#   table_ref - The destination table reference\n",
        "#   job_config - Our schema configuration\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the job to complete before proceeding\n",
        "# This blocks execution until the upload finishes\n",
        "job.result()"
      ],
      "metadata": {
        "id": "i1qs04HUE4xU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}