{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependência"
      ],
      "metadata": {
        "id": "4qTABpnEL21u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "# !pip install gcloud\n",
        "# !gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ],
      "metadata": {
        "id": "FSEb7VzsL8m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "pJ8VUCvbqfWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Human Resources data from Excel file\n",
        "df = pd.read_excel(\"Base_Estadic_2023(2).xlsx\", sheet_name='Recursos Humanos')\n",
        "\n",
        "# Create two separate dataframes for different question groups (EREH01* and EREH03*)\n",
        "df1 = df[['Sigla UF', 'PopUF', 'EREH0111', 'EREH0112', 'EREH0113', 'EREH0114', 'EREH0115']]\n",
        "df2 = df[['Sigla UF', 'PopUF', 'EREH0311', 'EREH0312', 'EREH0313', 'EREH0314', 'EREH0315']]\n",
        "\n",
        "# Rename columns to meaningful Portuguese names\n",
        "df1 = df1.rename(columns={\n",
        "    'EREH0111': 'Estatutários',\n",
        "    'EREH0112': 'Celetistas',\n",
        "    'EREH0113': 'Somente comissionados',\n",
        "    'EREH0114': 'Estagiários',\n",
        "    'EREH0115': 'Sem vínculo permanente',\n",
        "    'PopUF': 'pop_projetada',\n",
        "    'Sigla UF': 'sigla_uf'\n",
        "})\n",
        "\n",
        "df2 = df2.rename(columns={\n",
        "    'EREH0311': 'Estatutários',\n",
        "    'EREH0312': 'Celetistas',\n",
        "    'EREH0313': 'Somente comissionados',\n",
        "    'EREH0314': 'Estagiários',\n",
        "    'EREH0315': 'Sem vínculo permanente',\n",
        "    'PopUF': 'pop_projetada',\n",
        "    'Sigla UF': 'sigla_uf'\n",
        "})\n",
        "\n",
        "# Transform both dataframes from wide to long format\n",
        "df1 = df1.melt(\n",
        "    id_vars=['sigla_uf', 'pop_projetada'],\n",
        "    value_vars=['Estatutários', 'Celetistas', 'Somente comissionados', 'Estagiários', 'Sem vínculo permanente'],\n",
        "    var_name='tipo_vinculo',\n",
        "    value_name='quantidade_vinculos'\n",
        ")\n",
        "\n",
        "df2 = df2.melt(\n",
        "    id_vars=['sigla_uf', 'pop_projetada'],\n",
        "    value_vars=['Estatutários', 'Celetistas', 'Somente comissionados', 'Estagiários', 'Sem vínculo permanente'],\n",
        "    var_name='tipo_vinculo',\n",
        "    value_name='quantidade_vinculos'\n",
        ")\n",
        "\n",
        "# Combine both dataframes\n",
        "df = pd.concat([df1, df2])\n",
        "\n",
        "# Clean and convert numeric values\n",
        "df['quantidade_vinculos'] = pd.to_numeric(df['quantidade_vinculos'], errors='coerce')\n",
        "df['quantidade_vinculos'] = df['quantidade_vinculos'].fillna(0)\n",
        "\n",
        "# Select and reorder columns\n",
        "df = df[['tipo_vinculo', 'sigla_uf', 'quantidade_vinculos']]\n",
        "\n",
        "# Aggregate data by UF and employment type\n",
        "df = df.groupby(['sigla_uf', 'tipo_vinculo'], as_index=False)['quantidade_vinculos'].sum()\n",
        "\n",
        "# Add year column and finalize column order\n",
        "df['ano'] = 2023\n",
        "df = df[['ano', 'tipo_vinculo', 'sigla_uf', 'quantidade_vinculos']]"
      ],
      "metadata": {
        "id": "7IK53QHhARSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wEVs2CnnI2L",
        "outputId": "33896003-374c-4317-e734-3df541978c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135 entries, 0 to 134\n",
            "Data columns (total 4 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   ano                  135 non-null    int64  \n",
            " 1   tipo_vinculo         135 non-null    object \n",
            " 2   sigla_uf             135 non-null    object \n",
            " 3   quantidade_vinculos  135 non-null    float64\n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 4.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "MYeq4VS_L6vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the BigQuery table schema with field types and descriptions\n",
        "schema = [\n",
        "    bigquery.SchemaField('ano', 'INTEGER', description='Ano de referencia da informacao'),\n",
        "    bigquery.SchemaField('tipo_vinculo', 'STRING', description='Tipo de vinculo.'),\n",
        "    bigquery.SchemaField('sigla_uf', 'STRING', description='Sigla da Unidade da Federação.'),\n",
        "    bigquery.SchemaField('quantidade_vinculos', 'INTEGER', description='Quantidade de vinculos')\n",
        "]\n",
        "\n",
        "# Initialize connection to BigQuery client for the specified project\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create reference to the target dataset\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Create reference to the target table following naming convention: FONTE_algo_intuitivo_dado\n",
        "table_ref = dataset_ref.table('ESTADIC_quantidade_vinculos_v1')\n",
        "\n",
        "# Configure the data upload job with the defined schema\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Execute the job to upload DataFrame to BigQuery\n",
        "job = client.load_table_from_dataframe(\n",
        "    dataframe=df,\n",
        "    destination=table_ref,\n",
        "    job_config=job_config\n",
        ")\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()"
      ],
      "metadata": {
        "id": "WtL6vmwbAfrH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}