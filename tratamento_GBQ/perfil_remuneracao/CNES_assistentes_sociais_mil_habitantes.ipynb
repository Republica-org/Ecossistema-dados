{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "KK9fSGl9uxnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs0PP0Oiuzc8",
        "outputId": "629108a9-c681-4b79-dca9-738a0a25e08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gcloud\n",
            "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (0.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.70.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.12/dist-packages (from gcloud) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (4.9.1)\n",
            "Building wheels for collected packages: gcloud\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602927 sha256=1601d8c99c66a48cb129d89a20fec7b3fed8ad7b106423ae8ca7df682210d294\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/62/75/3d74209bfebb8805823ae74afa28653aa1ea76d8b5a9d741ff\n",
            "Successfully built gcloud\n",
            "Installing collected packages: gcloud\n",
            "Successfully installed gcloud-0.18.3\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=ABTdmTHkelkespr8uY8MYqUJxwTchE&prompt=consent&token_usage=remote&access_type=offline&code_challenge=Frte7S5t_QkYuaoRxQipFAZuMtnrK_lxI_cOROFzFg4&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVMBsJgDbnBlobiP21oPxDC1BlaX3l1qiDyIecxs403siwUWoDds3pXPjnf3mVyXB4Wedg\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "WIizHjyru0x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SQL query to be executed in Google BigQuery.\n",
        "# This query selects all columns from the `CNES_profissionais_saude_ocupacao_publico` table,\n",
        "# ordering the results by the 'ano' column in descending order.\n",
        "query = \"\"\"\n",
        "  SELECT * FROM `repositoriodedadosgpsp.Datalake.CNES_profissionais_saude_ocupacao_publico` order by ano desc\n",
        "        \"\"\"\n",
        "# Execute the query using pandas_gbq.read_gbq and load the result into a pandas DataFrame called 'df'.\n",
        "# The 'project_id' specifies the Google Cloud Project to use.\n",
        "df = pandas_gbq.read_gbq(query, project_id='repositoriodedadosgpsp')\n",
        "\n",
        "# Create a new column 'tipo_2'.\n",
        "# It uses np.where to check if the 'tipo_ocupacao' column contains the string 'Assistentes sociais e economistas domésticos'.\n",
        "# If it does, the value in 'tipo_2' is set to 'Assistentes sociais e economistas domésticos'; otherwise, it retains the original 'tipo_ocupacao' value.\n",
        "df['tipo_2'] = np.where(df['tipo_ocupacao'].str.contains('Assistentes sociais e economistas domésticos'),'Assistentes sociais e economistas domésticos',df['tipo_ocupacao'])\n",
        "\n",
        "# Filter the DataFrame 'df'.\n",
        "# It keeps only the rows where the 'tipo_2' column is exactly 'Assistentes sociais e economistas domésticos'\n",
        "# AND the 'ano' column is greater than 2017.\n",
        "df = df[(df['tipo_2']=='Assistentes sociais e economistas domésticos') & (df['ano']>2017)]\n",
        "\n",
        "# Read population data from a local CSV file named \"Censo_previa_pop.csv\" into a new DataFrame called 'pop'.\n",
        "# The separator for the CSV is specified as a comma.\n",
        "pop = pd.read_csv(\"Censo_previa_pop.csv\", sep=',')\n",
        "\n",
        "# Rename columns in the 'pop' DataFrame for better clarity and consistency with the 'df' DataFrame.\n",
        "pop = pop.rename(columns={'CodMun': 'id_municipio', 'Sigla UF': 'UF', 'PopMun': 'POPULAÇÃO', 'Mun': 'NOME DO MUNICÍPIO'})\n",
        "\n",
        "# Convert the 'id_municipio' column in the 'df' DataFrame to a numeric data type to ensure proper merging later.\n",
        "df['id_municipio'] = pd.to_numeric(df['id_municipio'])\n",
        "\n",
        "# Create a pivot table 'x' from the 'df' DataFrame.\n",
        "# This aggregates (sums) the 'quantidade_vinculos' (number of employment links)\n",
        "# for each unique combination of 'ano', 'sigla_uf', 'id_municipio', and 'tipo_2'.\n",
        "x=df.pivot_table(index=['ano','sigla_uf'  ,'id_municipio','tipo_2'], values='quantidade_vinculos',aggfunc=np.sum)\n",
        "# Convert the pivot table 'x' (which is a pandas Series with a MultiIndex) into a DataFrame 'y'.\n",
        "y = pd.DataFrame(x)\n",
        "# Reset the index of DataFrame 'y' to turn the index levels into columns. The result is assigned back to 'df'.\n",
        "df = y.reset_index()\n",
        "\n",
        "# Merge the 'df' DataFrame with a selection of columns from the 'pop' DataFrame.\n",
        "# The merge is performed on the 'id_municipio' column, which exists in both DataFrames.\n",
        "# The result is stored in a new DataFrame 'df1' and sorted by 'quantidade_vinculos' in descending order.\n",
        "df1= df.merge(pop[['UF','NOME DO MUNICÍPIO','id_municipio','POPULAÇÃO']], left_on='id_municipio',right_on='id_municipio').sort_values('quantidade_vinculos', ascending=False)\n",
        "\n",
        "# Calculate the rate of professionals per 1,000 people and create a new column 'taxa'.\n",
        "# This is done by dividing the 'quantidade_vinculos' by the 'POPULAÇÃO' and multiplying by 1000.\n",
        "df1['taxa'] = df1['quantidade_vinculos']/df1['POPULAÇÃO']*1000\n",
        "\n",
        "# Select a subset of columns from 'df1' and rename them to create the final DataFrame structure.\n",
        "# The result is assigned back to 'df'.\n",
        "df = df1[['ano', 'sigla_uf', 'id_municipio', 'tipo_2', 'quantidade_vinculos',\n",
        "        'NOME DO MUNICÍPIO', 'POPULAÇÃO', 'taxa']].rename(columns={'tipo_2':'tipo_ocupacao','UF':'sigla_uf', 'NOME DO MUNICÍPIO':'nome_municipio','POPULAÇÃO':'populacao_domiciliada' })\n",
        "\n",
        "# Reorder the columns in the final DataFrame 'df' to a specific desired order.\n",
        "df= df[['ano', 'sigla_uf', 'nome_municipio','id_municipio','populacao_domiciliada', 'tipo_ocupacao',\n",
        "       'quantidade_vinculos',\n",
        "       'taxa']]\n",
        "\n",
        "# Print a concise summary of the DataFrame 'df'.\n",
        "# This includes the index dtype and columns, non-null values, and memory usage.\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "5yim8Lxku47x",
        "outputId": "834e3f4b-2684-4b3a-eb9c-81d473962ddd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pandas_gbq' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3035444842.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mrepositoriodedadosgpsp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatalake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNES_profissionais_saude_ocupacao_publico\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0morder\u001b[0m \u001b[0mby\u001b[0m \u001b[0mano\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpandas_gbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repositoriodedadosgpsp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo_ocupacao'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Assistentes sociais e economistas domésticos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Assistentes sociais e economistas domésticos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tipo_ocupacao'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pandas_gbq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "ZdY0P79iwFMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the bigquery library from google.cloud\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize the BigQuery client, specifying the Google Cloud project ID.\n",
        "# This client object is used to interact with the BigQuery API.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create a reference to the BigQuery dataset named 'perfil_remuneracao'.\n",
        "# This does not create the dataset, but points to it.\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Define the schema for the destination BigQuery table.\n",
        "# The schema is a list of SchemaField objects, where each object defines a column's:\n",
        "# 1. Name (e.g., 'ano')\n",
        "# 2. Data type (e.g., 'INTEGER')\n",
        "# 3. Description (e.g., 'Ano de referencia da informacao')\n",
        "schema=[bigquery.SchemaField('ano','INTEGER',description='Ano de referencia da informacao'),\n",
        " bigquery.SchemaField('sigla_uf','STRING',description='Sigla da Unidade da Federação.'),\n",
        " bigquery.SchemaField('nome_municipio','STRING',description='Nome do município da observação'),\n",
        " bigquery.SchemaField('id_municipio','FLOAT',description='Identificador do município pelo IBGE'),\n",
        " bigquery.SchemaField('populacao_domiciliada','FLOAT',description='População domiciliada (prévia do Censo 2022)'),\n",
        " bigquery.SchemaField('tipo_ocupacao','STRING',description='Qual a ocupação daquele vínculo'),\n",
        " bigquery.SchemaField('quantidade_vinculos','INTEGER',description='Quantidade de vinculos'),\n",
        " bigquery.SchemaField('taxa','Float',description='Taxa de Assistentes sociais e economistas domésticos por 1000 habitantes')\n",
        " ]\n",
        "\n",
        "# Create a reference to the target table within the dataset specified earlier.\n",
        "# The table will be named 'CNES_assistentes_sociais_mil_habitantes_v1'.\n",
        "table_ref = dataset_ref.table('CNES_assistentes_sociais_mil_habitantes_v1') # table name in the format SOURCE_intuitive_data_name\n",
        "\n",
        "# Configure the load job by creating a LoadJobConfig object.\n",
        "# Here, we specify the schema that BigQuery should use when creating or appending to the table.\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Start the job to load data from the pandas DataFrame 'df' into the specified BigQuery table ('table_ref').\n",
        "# The job is configured with the previously defined 'job_config'.\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the load job to complete and retrieve the result.\n",
        "# This line is blocking and will pause the script's execution until the upload is finished.\n",
        "job.result()"
      ],
      "metadata": {
        "id": "bTvJnlgt7nOT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}