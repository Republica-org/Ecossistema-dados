{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YZOZNb_-1HA",
        "outputId": "6cd9f1df-1940-4d69-aeb5-52f054f60087"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gcloud\n",
            "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from gcloud) (0.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.11/dist-packages (from gcloud) (1.70.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.11/dist-packages (from gcloud) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gcloud) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (4.9.1)\n",
            "Building wheels for collected packages: gcloud\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602927 sha256=780f4b1b515041506acd7a202d86f758235f7d85e1698d59958bd69f94929ee6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/e8/d1/cb82a63f69083ea485de71d14248b8d145f1af46a41578be9c\n",
            "Successfully built gcloud\n",
            "Installing collected packages: gcloud\n",
            "Successfully installed gcloud-0.18.3\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=mlCM8tta0qeRjvOQDXFBzjkQ0dJxpg&prompt=consent&token_usage=remote&access_type=offline&code_challenge=dCJBeZgrSjWiRevH5pJqRgc0sHtIJVqEwawK_HjpCZ8&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVMBsJi6pyhsEaMfj5GBt_EwgOUXxGFnPZV8CKby6mI3Bs67qBxzOA_iOPjUspnyKTlHBw\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "pJ8VUCvbqfWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Google Cloud project ID\n",
        "project_id = \"repositoriodedadosgpsp\"\n",
        "\n",
        "# SQL query to fetch all data from the ESTADIC_quantidade_vinculos_v1 table\n",
        "query = \"\"\"\n",
        "SELECT * FROM `repositoriodedadosgpsp.perfil_remuneracao.ESTADIC_quantidade_vinculos_v1`\n",
        "\"\"\"\n",
        "\n",
        "# Execute query and load results into DataFrame\n",
        "df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "\n",
        "# Display first few rows of the data\n",
        "print(df.head())\n",
        "\n",
        "# Create pivot table to calculate total employment by state\n",
        "y = df.pivot_table(\n",
        "    index={'sigla_uf'},  # Group by state abbreviation\n",
        "    values='quantidade_vinculos',  # Aggregate employment numbers\n",
        "    aggfunc=np.sum  # Sum all employment types\n",
        ")\n",
        "\n",
        "# Convert pivot table to DataFrame and reset index\n",
        "y = pd.DataFrame(y)\n",
        "total = y.reset_index()\n",
        "\n",
        "# Rename column for clarity\n",
        "total = total.rename(columns={'quantidade_vinculos': 'total_estado'})\n",
        "\n",
        "# Merge totals back with original data\n",
        "df1 = df.merge(\n",
        "    total,\n",
        "    right_on='sigla_uf',\n",
        "    left_on='sigla_uf'\n",
        ")\n",
        "\n",
        "# Example check for Espírito Santo state data\n",
        "df1[df1['sigla_uf'] == \"ES\"]\n",
        "\n",
        "# Special handling for Rondônia state (setting total to 1)\n",
        "df1.loc[df1['sigla_uf'] == 'RO', 'total_estado'] = 1\n",
        "\n",
        "# Verify Rondônia data\n",
        "df1[df1['sigla_uf'] == 'RO']\n",
        "\n",
        "# Update main DataFrame with merged data\n",
        "df = df1"
      ],
      "metadata": {
        "id": "eTHe63EYFAdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wEVs2CnnI2L",
        "outputId": "f5480015-3a69-495a-c931-8985c6f50c97"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135 entries, 0 to 134\n",
            "Data columns (total 5 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   ano                  135 non-null    Int64 \n",
            " 1   tipo_vinculo         135 non-null    object\n",
            " 2   sigla_uf             135 non-null    object\n",
            " 3   quantidade_vinculos  135 non-null    Int64 \n",
            " 4   total_estado         135 non-null    Int64 \n",
            "dtypes: Int64(3), object(2)\n",
            "memory usage: 5.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "_Gg9lWmiAl46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the BigQuery table schema with Portuguese descriptions\n",
        "schema = [\n",
        "    bigquery.SchemaField('ano', 'INTEGER', description='Ano de referencia da informacao'),\n",
        "    bigquery.SchemaField('tipo_vinculo', 'STRING', description='Tipo de vinculo.'),\n",
        "    bigquery.SchemaField('sigla_uf', 'STRING', description='Sigla da Unidade da Federação.'),\n",
        "    bigquery.SchemaField('quantidade_vinculos', 'INTEGER', description='Quantidade de vinculos'),\n",
        "    bigquery.SchemaField('total_estado', 'INTEGER', description='Total de vínculos daquela UF')\n",
        "]\n",
        "\n",
        "# Initialize BigQuery client connection\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create reference to target dataset\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Create reference to target table with standardized naming convention:\n",
        "# FONTE_algo_intuitivo_dado (ESTADIC_quantidade_vinculos_mapa_v2)\n",
        "table_ref = dataset_ref.table('ESTADIC_quantidade_vinculos_mapa_v2')\n",
        "\n",
        "# Configure the load job with our schema definition\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=schema,\n",
        "    # Optional parameters (commented out):\n",
        "    # write_disposition=\"WRITE_TRUNCATE\",  # Overwrites table if exists\n",
        "    # create_disposition=\"CREATE_IF_NEEDED\"  # Default behavior\n",
        ")\n",
        "\n",
        "# Execute the load job to upload DataFrame to BigQuery\n",
        "job = client.load_table_from_dataframe(\n",
        "    dataframe=df,\n",
        "    destination=table_ref,\n",
        "    job_config=job_config\n",
        ")\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()"
      ],
      "metadata": {
        "id": "UTk-ZTkxFHWz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}