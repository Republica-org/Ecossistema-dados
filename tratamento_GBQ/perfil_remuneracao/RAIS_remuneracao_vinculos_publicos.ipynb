{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "4iGy8B2CxTXw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYLu-ty_ts0q"
      },
      "outputs": [],
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "YeXiMskKxfJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Google Cloud project ID.\n",
        "project_id = \"repositoriodedadosgpsp\"\n",
        "\n",
        "# Define the SQL query to select all data from the specified BigQuery table.\n",
        "query = \"\"\"\n",
        "SELECT * FROM `repositoriodedadosgpsp.Datalake.RAIS_remuneracao_vinculos_publicos_v4`\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and load the results into a pandas DataFrame.\n",
        "df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify the data.\n",
        "print(df.head())\n",
        "\n",
        "# 1. Load the original IPCA (inflation index) data from a CSV file.\n",
        "df_ipca = pd.read_csv('it-ipca-formatado.csv')\n",
        "\n",
        "# 2. Extract the years from the column headers and create a list.\n",
        "anos = df_ipca.columns.str.extract('(\\d{4})')[0].tolist()\n",
        "# Extract the IPCA values from the first row and create a list.\n",
        "valores = df_ipca.iloc[0].tolist()\n",
        "\n",
        "# 3. Create a new DataFrame from the extracted years and values.\n",
        "df_ipca_transformado = pd.DataFrame({\n",
        "    'Ano': anos,\n",
        "    'IPCA_acumulado': valores\n",
        "})\n",
        "\n",
        "# 4. Define a function to clean and convert IPCA values.\n",
        "def converter_valor(valor):\n",
        "    # Check if the value is a string.\n",
        "    if isinstance(valor, str):\n",
        "        # Return None for '...' placeholder.\n",
        "        if valor == '...':\n",
        "            return None\n",
        "        # Replace comma with a dot for decimal conversion and cast to float.\n",
        "        return float(valor.replace(',', '.'))\n",
        "    # Return the value as is if it's not a string.\n",
        "    return valor\n",
        "\n",
        "# Apply the cleaning function to the 'IPCA_acumulado' column.\n",
        "df_ipca_transformado['IPCA_acumulado'] = df_ipca_transformado['IPCA_acumulado'].apply(converter_valor)\n",
        "\n",
        "# 5. Remove rows with null values (optional step).\n",
        "df_ipca_transformado = df_ipca_transformado.dropna()\n",
        "\n",
        "# 6. Convert the 'Ano' column to an integer data type.\n",
        "df_ipca_transformado['Ano'] = df_ipca_transformado['Ano'].astype(int)\n",
        "\n",
        "# 7. Display the transformed and cleaned IPCA DataFrame.\n",
        "print(df_ipca_transformado)\n",
        "\n",
        "# 8. Save the transformed DataFrame to a new CSV file, without the index.\n",
        "df_ipca_transformado.to_csv('ipca_simplificado.csv', index=False)\n",
        "\n",
        "# Rename the 'Ano' column to 'ano' to match the main DataFrame for merging.\n",
        "df_ipca_transformado = df_ipca_transformado.rename(columns={'Ano': 'ano'})\n",
        "# Ensure the 'ano' column in the IPCA DataFrame is of integer type.\n",
        "df_ipca_transformado['ano'] = df_ipca_transformado['ano'].astype(int)\n",
        "# Ensure the 'ano' column in the main DataFrame is of integer type.\n",
        "df['ano'] = df['ano'].astype(int)\n",
        "\n",
        "# Merge the main DataFrame with the IPCA DataFrame based on the 'ano' column.\n",
        "df_completo = pd.merge(\n",
        "    df,\n",
        "    df_ipca_transformado,\n",
        "    on='ano',\n",
        "    how='left' # Use a left join to keep all records from the main DataFrame.\n",
        ")\n",
        "\n",
        "# Calculate the correction factor based on a reference value and the accumulated IPCA.\n",
        "df_completo['fator_correcao'] = (7100.5 / df_completo['IPCA_acumulado'])\n",
        "\n",
        "# Calculate the adjusted average remuneration by applying the correction factor.\n",
        "df_completo['media_remuneracao_ajustada']= df_completo['media_remuneracao'] * (df_completo['fator_correcao'])\n",
        "\n",
        "# Select and reorder the columns for the final DataFrame.\n",
        "df_completo = df_completo[['ano', 'variavel', 'categoria', 'media_remuneracao',\n",
        "       'fator_correcao', 'media_remuneracao_ajustada']]"
      ],
      "metadata": {
        "id": "ETM6ckROxgY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjugzNpQQ8YY",
        "outputId": "b3632fc7-3962-41c3-9fad-fa6c2fec317d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 519 entries, 0 to 518\n",
            "Data columns (total 6 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   ano                         519 non-null    int64  \n",
            " 1   variavel                    519 non-null    object \n",
            " 2   categoria                   519 non-null    object \n",
            " 3   media_remuneracao           519 non-null    float64\n",
            " 4   fator_correcao              519 non-null    float64\n",
            " 5   media_remuneracao_ajustada  519 non-null    float64\n",
            "dtypes: float64(3), int64(1), object(2)\n",
            "memory usage: 24.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "haJs1SDgxxWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the BigQuery table, specifying column names, data types, and descriptions.\n",
        "schema=[bigquery.SchemaField('ano','INTEGER',description='Ano de referência'),\n",
        " bigquery.SchemaField('variavel','STRING',description='De qual variável aquela remuneração se refere'),\n",
        " bigquery.SchemaField('categoria','STRING',description='Categoria dentro daquela variável'),\n",
        " bigquery.SchemaField('media_remuneracao','FLOAT',description='Valor nominal da média de remuneração daquele ano'),\n",
        "bigquery.SchemaField('fator_correcao','FLOAT',description='índice para correção monetária baseando-se no IPCA para dezembro de 2022'),\n",
        "bigquery.SchemaField('media_remuneracao_ajustada','FLOAT',description='Valor nominal da média de remuneração daquele ano ajustado para dezembro de 2022')\n",
        " ]\n",
        "\n",
        " ## Uploading to the datalake\n",
        " # Initialize the BigQuery client with the specified project ID.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "# Get a reference to the 'perfil_remuneracao' dataset.\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Get a reference to the target table within the dataset.\n",
        "table_ref = dataset_ref.table('RAIS_remuneracao_vinculos_publicos_v3') # Table name follows the pattern SOURCE_intuitive_name_data\n",
        "# Configure the load job, applying the predefined schema.\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "# Start the job to load the DataFrame into the specified BigQuery table.\n",
        "job = client.load_table_from_dataframe(df_completo, table_ref, job_config=job_config)\n",
        "# Wait for the load job to complete and get the result.\n",
        "job.result()"
      ],
      "metadata": {
        "id": "sX48vkztxzso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}