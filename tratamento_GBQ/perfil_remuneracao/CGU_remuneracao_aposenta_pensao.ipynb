{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "GadLvAxVBztg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NTT_ggqBwYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478a1b6a-e779-4c1e-98e8-8220a6158394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcloud in /usr/local/lib/python3.12/dist-packages (0.18.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (0.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.70.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.12/dist-packages (from gcloud) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (4.9.1)\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=WN0z8Fz42ZtajOnr23RuBp3tsR4joo&prompt=consent&token_usage=remote&access_type=offline&code_challenge=hRZ18DlXMnJS5R9DFno9pt8WbwRiK-bEURg4SGRmECo&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVMBsJiioePAnOLZxp4KD4jv-cWSdxL_YwjyknHP8dowzFcCRMhqZZ4RZrYb1gRPjjFlDA\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "ovGVPGiTB4t3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mPQM3jkBwYg"
      },
      "source": [
        "Foi feito o download do mês de novembro da remuneração dos aposentados e pensionistas civis e reserva/reforma militares"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the BigQuery client, specifying the Google Cloud project ID.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "# Define a list of years to process.\n",
        "anos = [2020,2021,2022,2023,2024]\n",
        "# Loop through each year in the list.\n",
        "for ano in anos:\n",
        "  # Define a formatted SQL query to be executed for each year.\n",
        "  query = f\"\"\"\n",
        "  # Use a Common Table Expression (CTE) to calculate the average remuneration for different groups.\n",
        "  WITH Medias AS (\n",
        "    SELECT 'aposentados_civil' AS detalhamento, AVG(REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS media\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_siape_aposentados_remuneracao`\n",
        "   UNION ALL\n",
        "   SELECT 'pensionista_civil' AS detalhamento, AVG(REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS media\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_siape_pensionista_remuneracao`\n",
        "   UNION ALL\n",
        "   SELECT 'militar_reserva_reforma' AS detalhamento, AVG(REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS media\n",
        "   FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_militares_reserva_reforma_remuneracao`\n",
        "   UNION ALL\n",
        "   SELECT 'pensionista_militar' AS detalhamento, AVG(REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS media\n",
        "   FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_militares_pensionistas_remuneracao`\n",
        "  ),\n",
        "\n",
        "  # Use a second CTE to calculate the median remuneration for the same groups.\n",
        "  Medianas AS (\n",
        "  SELECT 'aposentados_civil' AS detalhamento,\n",
        "         IF(MOD(total_count, 2) = 1, REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "         (REMUNERACAO_BASICA_BRUTA_EM_REAIS + LAG(REMUNERACAO_BASICA_BRUTA_EM_REAIS, 1) OVER(ORDER BY row_number)) / 2) AS mediana\n",
        "  FROM (\n",
        "    SELECT REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "           COUNT(REMUNERACAO_BASICA_BRUTA_EM_REAIS) OVER() AS total_count,\n",
        "           ROW_NUMBER() OVER(ORDER BY REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS row_number\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_siape_aposentados_remuneracao`\n",
        "  )\n",
        "  WHERE row_number IN (FLOOR((total_count + 1) / 2), CEIL((total_count + 1) / 2))\n",
        "\n",
        "  UNION ALL\n",
        "\n",
        "  SELECT 'pensionista_civil' AS detalhamento,\n",
        "         IF(MOD(total_count, 2) = 1, REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "         (REMUNERACAO_BASICA_BRUTA_EM_REAIS + LAG(REMUNERACAO_BASICA_BRUTA_EM_REAIS, 1) OVER(ORDER BY row_number)) / 2) AS mediana\n",
        "  FROM (\n",
        "    SELECT REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "           COUNT(REMUNERACAO_BASICA_BRUTA_EM_REAIS) OVER() AS total_count,\n",
        "           ROW_NUMBER() OVER(ORDER BY REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS row_number\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_siape_pensionista_remuneracao`\n",
        "\n",
        "  )\n",
        "  WHERE row_number IN (FLOOR((total_count + 1) / 2), CEIL((total_count + 1) / 2))\n",
        "  UNION ALL\n",
        "\n",
        "  SELECT 'militar_reserva_reforma' AS detalhamento,\n",
        "         IF(MOD(total_count, 2) = 1, REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "         (REMUNERACAO_BASICA_BRUTA_EM_REAIS + LAG(REMUNERACAO_BASICA_BRUTA_EM_REAIS, 1) OVER(ORDER BY row_number)) / 2) AS mediana\n",
        "  FROM (\n",
        "    SELECT REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "           COUNT(REMUNERACAO_BASICA_BRUTA_EM_REAIS) OVER() AS total_count,\n",
        "           ROW_NUMBER() OVER(ORDER BY REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS row_number\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_militares_reserva_reforma_remuneracao`\n",
        "\n",
        "  )\n",
        "  WHERE row_number IN (FLOOR((total_count + 1) / 2), CEIL((total_count + 1) / 2))\n",
        "  UNION ALL\n",
        "\n",
        "  SELECT 'pensionista_militar' AS detalhamento,\n",
        "         IF(MOD(total_count, 2) = 1, REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "         (REMUNERACAO_BASICA_BRUTA_EM_REAIS + LAG(REMUNERACAO_BASICA_BRUTA_EM_REAIS, 1) OVER(ORDER BY row_number)) / 2) AS mediana\n",
        "  FROM (\n",
        "    SELECT REMUNERACAO_BASICA_BRUTA_EM_REAIS,\n",
        "           COUNT(REMUNERACAO_BASICA_BRUTA_EM_REAIS) OVER() AS total_count,\n",
        "           ROW_NUMBER() OVER(ORDER BY REMUNERACAO_BASICA_BRUTA_EM_REAIS) AS row_number\n",
        "    FROM `repositoriodedadosgpsp.portal_transparencia_cgu.{ano}_nov_militares_pensionistas_remuneracao`\n",
        "\n",
        "  )\n",
        "  WHERE row_number IN (FLOOR((total_count + 1) / 2), CEIL((total_count + 1) / 2))\n",
        "\n",
        "\n",
        "  )\n",
        "\n",
        "  # Join the results from the Medias and Medianas CTEs.\n",
        "  SELECT\n",
        "    M.detalhamento,\n",
        "  M.media,\n",
        "  MD.mediana\n",
        "FROM Medias M\n",
        "LEFT JOIN Medianas MD\n",
        "ON M.detalhamento = MD.detalhamento\n",
        "\"\"\"\n",
        "\n",
        "  # Execute the query for the current year.\n",
        "  query_job = client.query(query)\n",
        "  # Create a dynamic DataFrame name based on the year (e.g., \"df2020\").\n",
        "  df_name = f\"df{ano}\"\n",
        "  # Execute code to create a DataFrame with the dynamic name from the query result.\n",
        "  exec(f\"{df_name} = query_job.to_dataframe()\")\n",
        "# Create a DataFrame for each year.\n",
        "\n",
        "# Define a list of years from 2021 to 2024 for concatenation.\n",
        "anos2 = [2021,2022,2023,2024]\n",
        "\n",
        "# This re-definition is redundant.\n",
        "anos2 = [2021,2022,2023,2024]\n",
        "# Manually add an 'ano' column to the 2020 DataFrame.\n",
        "df2020['ano'] = 2020\n",
        "# Filter out rows from df2020 where the 'mediana' is null.\n",
        "df2020= df2020[df2020['mediana'].notna()]\n",
        "\n",
        "# Loop through the remaining years to combine the DataFrames.\n",
        "for ano in anos2:\n",
        "   # Create the variable name for the DataFrame based on the year.\n",
        "    df_name = f\"df{ano}\"\n",
        "\n",
        "    # Retrieve the DataFrame corresponding to the year from the global scope.\n",
        "    df = globals().get(df_name)\n",
        "\n",
        "    if df is not None:  # Check if the DataFrame exists.\n",
        "        df['ano'] = ano  # Add the 'ano' column.\n",
        "        df = df[df['mediana'].notna()]  # Filter rows where 'mediana' is not NaN.\n",
        "\n",
        "        # Concatenate the current DataFrame to the main df2020 DataFrame.\n",
        "        df2020 = pd.concat([df2020, df], ignore_index=True)\n",
        "\n",
        "# Assign the final combined DataFrame to a new variable 'df'.\n",
        "df = df2020\n",
        "\n",
        "# Read inflation (IPCA) data from a CSV file.\n",
        "ipca = pd.read_csv('ipca_ibge_graf_cgu.csv')\n",
        "\n",
        "# Ensure the 'ano' column is of integer type for merging.\n",
        "df['ano'] = df['ano'].astype(int)\n",
        "\n",
        "# Merge the remuneration data with the inflation data on the 'ano' column.\n",
        "df1=df.merge(ipca[['ano','fator_correcao']], how='left', on='ano')\n",
        "\n",
        "# Calculate the inflation-adjusted average remuneration.\n",
        "df1['media_corrigido']= df1['media']*df1['fator_correcao']\n",
        "# Calculate the inflation-adjusted median remuneration.\n",
        "df1['mediana_corrigido']= df1['mediana']*df1['fator_correcao']\n",
        "\n",
        "# Select and reorder the columns for the final DataFrame.\n",
        "df1=df1[['ano','detalhamento', 'media', 'mediana','media_corrigido', 'mediana_corrigido','fator_correcao']]\n",
        "\n",
        "# Create a dictionary to map technical names to more readable descriptions.\n",
        "mapeamento_nomes = {\n",
        "    'pensionista_militar': 'Pensão Militar',\n",
        "    'aposentados_civil': 'Aposentadoria Civil',\n",
        "    'militar_reserva_reforma': 'Reserva ou Reforma Militar',\n",
        "    'pensionista_civil': 'Pensão Civil'\n",
        "}\n",
        "\n",
        "# Apply the name mapping to the 'detalhamento' column.\n",
        "df1['detalhamento'] = df1['detalhamento'].replace(mapeamento_nomes)"
      ],
      "metadata": {
        "id": "-ipUfPz5BR9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "T5EkKS32KtjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the bigquery library from google.cloud\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize the BigQuery client, specifying the Google Cloud project ID.\n",
        "# This client object is the main entry point for interacting with the BigQuery API.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create a reference to the BigQuery dataset named 'perfil_remuneracao'.\n",
        "# This object points to the dataset where the table will be created or updated.\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Define the schema for the destination BigQuery table.\n",
        "# The schema is a list of SchemaField objects, where each object defines a column's:\n",
        "# 1. Name (e.g., 'ano')\n",
        "# 2. Data type (e.g., 'INTEGER')\n",
        "# 3. Description (e.g., 'Ano de referencia da informacao')\n",
        "schema = [\n",
        "    bigquery.SchemaField('ano', 'INTEGER', description='Ano de referencia da informacao'),\n",
        "    bigquery.SchemaField('detalhamento', 'STRING', description='Detalhamento do grupo que estamos nos referindo'),\n",
        "    bigquery.SchemaField('media', 'FLOAT', description='Valor da média sem correção'),\n",
        "    bigquery.SchemaField('mediana', 'FLOAT', description='Valor da mediana sem correção'),\n",
        "    bigquery.SchemaField('media_corrigido', 'FLOAT', description='Valor da média com correção'),\n",
        "    bigquery.SchemaField('mediana_corrigido', 'FLOAT', description='Valor da mediana com correção'),\n",
        "    bigquery.SchemaField('fator_correcao', 'FLOAT', description='Fator de correção para dezembro de 2023')\n",
        "]\n",
        "\n",
        "# Create a reference to the target table within the dataset specified earlier.\n",
        "# The table will be named 'CGU_remuneracao_aposenta_pensao_v3'.\n",
        "table_ref = dataset_ref.table('CGU_remuneracao_aposenta_pensao_v3') # table name in the format SOURCE_something_intuitive_data\n",
        "\n",
        "# Configure the load job by creating a LoadJobConfig object.\n",
        "# Here, we specify the schema that BigQuery should use for the table. This ensures\n",
        "# that the columns in BigQuery have the correct data types and descriptions.\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Start the job to load data from the pandas DataFrame 'df1' into the specified BigQuery table ('table_ref').\n",
        "# The job is configured with the previously defined 'job_config'. This command sends the data to BigQuery.\n",
        "job = client.load_table_from_dataframe(df1, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the load job to complete and retrieve its result.\n",
        "# This line is blocking and will pause the script's execution until the data upload is finished.\n",
        "# It's crucial for ensuring the data is fully loaded before the script ends or proceeds.\n",
        "job.result()"
      ],
      "metadata": {
        "id": "vG6bR81qCJnE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}