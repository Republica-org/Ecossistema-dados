{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "S8P-5fizWEYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ],
      "metadata": {
        "id": "qbxYqBVhWGhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "1_HuiGWnWI_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library for data manipulation.\n",
        "import pandas as pd\n",
        "\n",
        "# Read data from a semicolon-separated CSV file into a pandas DataFrame.\n",
        "df = pd.read_csv('5680-085totalvinculospodernivelbrgrufdadosbrasil.csv', sep=';')\n",
        "\n",
        "# 1. Create a list of columns to keep fixed (year)\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Define the identifier variable(s) that will remain as columns during the unpivoting process.\n",
        "id_vars = ['ano']\n",
        "\n",
        "# 2. Derive sphere and power from the column names\n",
        "# First we do the melt to transform the columns into rows\n",
        "# The lines above are original comments in Portuguese.\n",
        "# Unpivot the DataFrame from a wide to a long format using the 'melt' function.\n",
        "# This converts all columns except 'ano' into rows, creating two new columns:\n",
        "# 'variavel' (original column names) and 'quantidade_vinculos' (their values).\n",
        "df_long = pd.melt(\n",
        "    df,\n",
        "    id_vars=id_vars,\n",
        "    var_name='variavel',\n",
        "    value_name='quantidade_vinculos'\n",
        ")\n",
        "\n",
        "# 3. Extract 'esfera' and 'poderes' from the column names\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Create a 'poderes' (powers) column by extracting the text between 'vinculos_' and the next '_' from 'variavel' and capitalizing it.\n",
        "df_long['poderes'] = df_long['variavel'].str.extract(r'vinculos_(.*?)_')[0].str.capitalize()\n",
        "# Create an 'esfera' (sphere) column by extracting the text after the last '_' from 'variavel' and capitalizing it.\n",
        "df_long['esfera'] = df_long['variavel'].str.extract(r'_(.*?)$')[0].str.capitalize()\n",
        "\n",
        "# 4. Correct special cases (like 'municipal' becoming 'Municipal')\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Ensure the values in the 'esfera' column are consistently named.\n",
        "df_long['esfera'] = df_long['esfera'].replace({\n",
        "    'Federal': 'Federal',\n",
        "    'Estadual': 'Estadual',\n",
        "    'Municipal': 'Municipal'\n",
        "})\n",
        "\n",
        "# 5. Calculate the annual proportion (prop_ano)\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Calculate the total 'quantidade_vinculos' for each year. 'transform' aligns the result back to the original DataFrame's shape.\n",
        "total_por_ano = df_long.groupby('ano')['quantidade_vinculos'].transform('sum')\n",
        "# Create a new column 'prop_ano' by dividing the links in each row by the total for that year.\n",
        "df_long['prop_ano'] = df_long['quantidade_vinculos'] / total_por_ano\n",
        "\n",
        "# 6. Select and order the desired columns\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Define the final list of columns to be included in the new DataFrame.\n",
        "colunas_finais = ['ano', 'quantidade_vinculos', 'prop_ano', 'esfera', 'poderes']\n",
        "# Create the final DataFrame by selecting the specified columns, sorting them, and resetting the index.\n",
        "df_final = df_long[colunas_finais].sort_values(['ano', 'esfera', 'poderes']).reset_index(drop=True)\n",
        "\n",
        "# 7. View the result\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Display the first 10 rows of the resulting DataFrame.\n",
        "df_final.head(10)\n",
        "\n",
        "# Assuming df_final is your current DataFrame\n",
        "# The line above is the original comment in Portuguese.\n",
        "\n",
        "# Step 1: Correct the 'esfera' column\n",
        "# The line above is the original comment in Portuguese.\n",
        "# This block appears to re-process the 'esfera' column, possibly to correct an earlier mistake.\n",
        "df_final['esfera'] = (\n",
        "    df_final['esfera']\n",
        "    .astype(str)  # Ensures it is treated as a string\n",
        "    .str.extract(r'_([^_]+)$')[0]  # Extracts text after the last underscore\n",
        "    .str.capitalize()  # Capitalizes the first letter\n",
        ")\n",
        "\n",
        "# Step 2: Correct the 'poderes' column to the Brazilian standard\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Replace values in the 'poderes' column to add the correct Portuguese accent marks.\n",
        "df_final['poderes'] = df_final['poderes'].replace({\n",
        "    'Judiciario': 'Judiciário',\n",
        "    'Legislativo': 'Legislativo',\n",
        "    'Executivo': 'Executivo'\n",
        "})\n",
        "\n",
        "# Define the order of the categories\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Create lists that define a custom, logical sort order for the 'poderes' and 'esfera' columns.\n",
        "ordem_poderes = ['Executivo', 'Legislativo', 'Judiciário']\n",
        "ordem_esfera = ['Federal', 'Estadual', 'Municipal']\n",
        "\n",
        "# Convert columns to categorical type with ordering\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Convert the 'poderes' column to an ordered Categorical type based on the defined order.\n",
        "df_final['poderes'] = pd.Categorical(\n",
        "    df_final['poderes'],\n",
        "    categories=ordem_poderes,\n",
        "    ordered=True\n",
        ")\n",
        "# Convert the 'esfera' column to an ordered Categorical type based on the defined order.\n",
        "df_final['esfera'] = pd.Categorical(\n",
        "    df_final['esfera'],\n",
        "    categories=ordem_esfera,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Sort the DataFrame\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Sort the DataFrame first by the custom 'poderes' order, then by the custom 'esfera' order, and finally by 'ano'.\n",
        "df_ordenado = df_final.sort_values(\n",
        "    ['poderes', 'esfera', 'ano'],\n",
        "    ascending=[True, True, True]  # Year in ascending order\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# View the result\n",
        "# The line above is the original comment in Portuguese.\n",
        "# Display the first 15 rows of the fully sorted DataFrame to see the pattern.\n",
        "df_ordenado.head(15)"
      ],
      "metadata": {
        "id": "TDmtvIQNWJ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "cs1U3oiKWg89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the bigquery library from google.cloud\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Define the schema for the destination BigQuery table.\n",
        "# The schema is a list of SchemaField objects, where each object defines a column's:\n",
        "# 1. Name (e.g., 'ano')\n",
        "# 2. Data type (e.g., 'INTEGER')\n",
        "# 3. Description (e.g., 'Ano de referência da observação')\n",
        "schema = [bigquery.SchemaField('ano', 'INTEGER', description= 'Ano de referência da observação'),\n",
        "          bigquery.SchemaField('quantidade_vinculos', 'INTEGER', description= 'Número total de vinculos observados'),\n",
        "          bigquery.SchemaField('prop_ano', 'FLOAT', description= 'proporção de vínculo em relação ao total naquele ano'),\n",
        "          bigquery.SchemaField('esfera', 'STRING', description= 'Nível da esfera do governo referente da observação'),\n",
        "          bigquery.SchemaField('poderes', 'STRING', description= 'Poder abrangente ao nível de esfera referente a observação')\n",
        "          ]\n",
        "\n",
        "## Uploading to datalake\n",
        "# The line above is the original comment in Portuguese.\n",
        "\n",
        "# Initialize the BigQuery client, specifying the Google Cloud project ID.\n",
        "# This client object is the main entry point for interacting with the BigQuery API.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create a reference to the BigQuery dataset named 'perfil_remuneracao'.\n",
        "# This object points to the dataset where the table will be created or updated.\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Create a reference to the target table within the dataset specified earlier.\n",
        "# The table will be named 'RAIS_poder_nivel_vinculos_v4'.\n",
        "table_ref = dataset_ref.table('RAIS_poder_nivel_vinculos_v4') # table name in the format SOURCE_something_intuitive_data\n",
        "\n",
        "# Configure the load job by creating a LoadJobConfig object.\n",
        "# Here, we specify the schema that BigQuery should use for the table. This ensures\n",
        "# that the columns in BigQuery have the correct data types and descriptions.\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Start the job to load data from the pandas DataFrame 'df_ordenado' into the specified BigQuery table ('table_ref').\n",
        "# The job is configured with the previously defined 'job_config'. This command sends the data to BigQuery.\n",
        "job = client.load_table_from_dataframe(df_ordenado, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the load job to complete and retrieve its result.\n",
        "# This line is blocking and will pause the script's execution until the data upload is finished.\n",
        "# It's crucial for ensuring the data is fully loaded before the script ends or proceeds.\n",
        "job.result()"
      ],
      "metadata": {
        "id": "8rpKQpVfWljW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}