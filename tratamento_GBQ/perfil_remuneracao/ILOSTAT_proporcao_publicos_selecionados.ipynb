{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "# !pip install gcloud\n",
        "# !gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ],
      "metadata": {
        "id": "wPIuGygRsaB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "maUl2LLbgg07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Google Cloud project ID\n",
        "project_id = \"repositoriodedadosgpsp\"\n",
        "\n",
        "# SQL query to fetch all data from the ILOSTAT table\n",
        "query = \"\"\"\n",
        "SELECT * FROM `repositoriodedadosgpsp.perfil_remuneracao.ILOSTAT_todos_paises_v3`\n",
        "\"\"\"\n",
        "\n",
        "# Execute query and load results into DataFrame\n",
        "df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "\n",
        "# Display first few rows of the data\n",
        "df.head()\n",
        "\n",
        "# List of selected countries for analysis\n",
        "paises_selecionados = ['South Africa', 'Argentina', 'Bolivia (Plurinational State of)',\n",
        "                      'Brazil', 'Chile', 'Colombia', 'United States of America',\n",
        "                      'France', 'Mexico', 'Peru', 'Uruguay']\n",
        "\n",
        "# Step 1: Find most recent year for each country (public sector only)\n",
        "ano_max_por_pais = df[df['setor'] == 'Public'].groupby('pais')['ano'].max().reset_index()\n",
        "\n",
        "# Step 2: Filter for only selected countries\n",
        "ano_max_selecionados = ano_max_por_pais[ano_max_por_pais['pais'].isin(paises_selecionados)]\n",
        "\n",
        "# Step 3: Merge with original DataFrame to get complete data\n",
        "df_final = pd.merge(\n",
        "    df,\n",
        "    ano_max_selecionados,\n",
        "    on=['pais', 'ano'],\n",
        "    how='inner'  # Keep only matching rows\n",
        ")\n",
        "\n",
        "# Step 4: Ensure only public sector data is included\n",
        "df_final = df_final[df_final['setor'] == 'Public'].reset_index(drop=True)\n",
        "\n",
        "# Country name mapping to Portuguese\n",
        "mapeamento_paises = {\n",
        "    'Argentina': 'Argentina',\n",
        "    'Bolivia (Plurinational State of)': 'Bolívia',\n",
        "    'Brazil': 'Brasil',\n",
        "    'Chile': 'Chile',\n",
        "    'Colombia': 'Colômbia',\n",
        "    'France': 'França',\n",
        "    'Mexico': 'México',\n",
        "    'Peru': 'Peru',\n",
        "    'Uruguay': 'Uruguai',\n",
        "    'United States of America': 'Estados Unidos',\n",
        "    'South Africa': 'África do Sul'\n",
        "}\n",
        "\n",
        "# Apply country name mapping\n",
        "df_final['pais'] = df_final['pais'].replace(mapeamento_paises)\n",
        "\n",
        "# Select final columns\n",
        "df_final = df_final[['pais', 'fonte_pesquisa', 'ano', 'prop']]\n",
        "\n",
        "# Rename columns for clarity\n",
        "df_final = df_final.rename(columns={\n",
        "    'ano': 'ano_pesquisa',\n",
        "    'prop': 'prop_vinculos_publicos'\n",
        "})"
      ],
      "metadata": {
        "id": "BPngOL2XsivH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "DDnAgrgZnvbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the BigQuery table schema with Portuguese descriptions\n",
        "schema = [\n",
        "    bigquery.SchemaField('pais', 'STRING', description='Nome do país selecionado'),\n",
        "    bigquery.SchemaField('fonte_pesquisa', 'STRING',\n",
        "                       description='De qual pesquisa nacional foi extraído aquele dado.'),\n",
        "    bigquery.SchemaField('ano_pesquisa', 'FLOAT',\n",
        "                       description='Ano de coleta da informação'),\n",
        "    bigquery.SchemaField('prop_vinculos_publicos', 'FLOAT',\n",
        "                       description='Proporção de vínculos públicos daquele país')\n",
        "]\n",
        "\n",
        "# Initialize BigQuery client connection\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create reference to target dataset\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Create reference to target table with standardized naming convention:\n",
        "# FONTE_algo_intuitivo_dado (ILOSTAT_proporcao_publicos_selecionados_v2)\n",
        "table_ref = dataset_ref.table('ILOSTAT_proporcao_publicos_selecionados_v2')\n",
        "\n",
        "# Configure the load job with our schema definition\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Execute the load job to upload DataFrame to BigQuery\n",
        "job = client.load_table_from_dataframe(\n",
        "    dataframe=df_final,\n",
        "    destination=table_ref,\n",
        "    job_config=job_config\n",
        ")\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()"
      ],
      "metadata": {
        "id": "0LdShD9FtkAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}