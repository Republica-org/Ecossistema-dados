{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "GFMRQ4PFC79N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypCHyA6IC5ve",
        "outputId": "8102c2de-179c-4f45-a710-8814d54d6fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcloud in /usr/local/lib/python3.12/dist-packages (0.18.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (0.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.70.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.12/dist-packages (from gcloud) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from gcloud) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=2.0.1->gcloud) (4.9.1)\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=Swt2zdm7VbM6DpNouSYHAEjWepeOka&prompt=consent&token_usage=remote&access_type=offline&code_challenge=CGy1U4jwbZEXg1aMYOaCF9AnHdd2qrA9YVYSkTTnniA&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVMBsJjY9Vd8FPf_KkdXsCk7BkWdxjxAfs7r_lNxSLC9KJS_Xcvw3538N9I088BaivFbYQ\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "# Install required Google Cloud packages (commented out as these are typically one-time setup commands)\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "# Import necessary Python libraries\n",
        "import pandas as pd                # Data manipulation and analysis\n",
        "import numpy as np                 # Numerical computing\n",
        "import time                        # Time-related functions\n",
        "import os                          # Operating system interfaces\n",
        "import pandas_gbq                  # Pandas integration with BigQuery\n",
        "from google.cloud import bigquery  # BigQuery client library\n",
        "import glob                        # File path pattern matching\n",
        "import openpyxl                    # Excel file handling\n",
        "import csv                         # CSV file handling\n",
        "import re                          # Regular expressions\n",
        "\n",
        "# Note: The actual imports remain exactly as in the original code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "l-yutMdrC_F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import pandas_gbq\n",
        "\n",
        "# Define the SQL query to select military pensioner data from a BigQuery table.\n",
        "query = \"\"\" SELECT ANO as ano, MES as mes, TIPO_PENSAO as tipo_pensao, DATA_INICIO_PENSAO as data_inicio_pensao,\n",
        "            1 as total FROM `repositoriodedadosgpsp.portal_transparencia_cgu.2024_4_militares_pensionistas_cadastro_v1`\n",
        "        \"\"\"\n",
        "\n",
        "# Execute the query and load the result into a pandas DataFrame.\n",
        "df = pandas_gbq.read_gbq(query, project_id='repositoriodedadosgpsp')\n",
        "# Display the initial DataFrame.\n",
        "df\n",
        "\n",
        "# Create a copy of the DataFrame (this copy is not used later).\n",
        "df1 = df\n",
        "\n",
        "# Check for null values in the 'data_inicio_pensao' column.\n",
        "pensoes = df['data_inicio_pensao'].isnull()\n",
        "# Count the number of null and non-null values.\n",
        "pensoes.value_counts()\n",
        "\n",
        "# Drop rows with any missing values.\n",
        "df = df.dropna() # 42 rows were dropped, equivalent to the total null values indicated above.\n",
        "# Display the DataFrame after dropping nulls.\n",
        "df\n",
        "\n",
        "# Convert the 'data_inicio_pensao' column to datetime objects.\n",
        "df['data_inicio_pensao'] = pd.to_datetime(df['data_inicio_pensao'], dayfirst=True, format= \"%d/%m/%Y\") #transforming into date\n",
        "# Extract the year from the 'data_inicio_pensao' column.\n",
        "df['ano_inicio_pensao'] = df['data_inicio_pensao'].dt.year #getting only the year\n",
        "# Define bin edges for creating decades.\n",
        "limites = [0, 1939, 1949, 1959, 1969, 1979, 1989, 1999, 2009, 2019, 2025]\n",
        "# Define labels for the decade bins.\n",
        "categorias = [1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020]\n",
        "\n",
        "# Create a new column by categorizing the 'ano_inicio_pensao' into decades.\n",
        "df['decada_inicio_pensao'] = pd.cut(df['ano_inicio_pensao'], bins=limites, labels=categorias)\n",
        "\n",
        "# Convert the 'decada_inicio_pensao' column to an integer type.\n",
        "df['decada_inicio_pensao'] = df['decada_inicio_pensao'].astype(int)\n",
        "\n",
        "# Define a dictionary to map detailed pension types to broader categories.\n",
        "pensoes = {\n",
        "    \"Filho\" : \"Filhos, netos, enteados ou menores em tutela\",\n",
        "    \"Filha\" : \"Filhos, netos, enteados ou menores em tutela\",\n",
        "    \"Menor sob guarda ou tutela\" : \"Filhos, netos, enteados ou menores em tutela\",\n",
        "    \"Neto (a)\" : \"Filhos, netos, enteados ou menores em tutela\",\n",
        "    \"Filho(a) adotivo ou Enteado(a)\" : \"Filhos, netos, enteados ou menores em tutela\",\n",
        "    \"Cônjuge / Viúva (o)\" : \"Cônjuge ou ex-cônjuge\",\n",
        "    \"C njuge / Vi va (o)\" : \"Cônjuge ou ex-cônjuge\",\n",
        "    \"Companheiro (a)\" : \"Cônjuge ou ex-cônjuge\",\n",
        "    \"Pessoa desquitada, separada judicialmente, divorciada do instituidor ou ex-convivente\" : \"Cônjuge ou ex-cônjuge\",\n",
        "    \"Mãe\":\"Pais\",\n",
        "    \"M e\":\"Pais\",\n",
        "    \"Pai\":\"Pais\",\n",
        "    \"Irmão (ã)\":\"Irmão (ã)\",\n",
        "    \"Irm o ( )\":\"Irmão (ã)\",\n",
        "    \"Ex-combatente (o próprio)\":\"Ex-combatente (o próprio)\",\n",
        "    \"Ex-combatente (o pr prio)\":\"Ex-combatente (o próprio)\",\n",
        "    \"Pessoa designada (Beneficiário instituído)\":\"Pessoa designada (Beneficiário instituído)\",\n",
        "    \"Pessoa designada (Benefici rio institu do)\":\"Pessoa designada (Beneficiário instituído)\",\n",
        "    \"Não informado\" : \"Não informado\",\n",
        "    \"N o informado\" : \"Não informado\",\n",
        "    \"Outros (Pessoas sem Vínculo Militar)\" : \"Outros (Pessoas sem Vínculo Militar)\",\n",
        "    \"Outros (Pessoas sem V nculo Militar)\" : \"Outros (Pessoas sem Vínculo Militar)\"\n",
        "    }\n",
        "\n",
        "# Define a function to apply the categorization using the dictionary.\n",
        "def categorizando(x):\n",
        "    if x in pensoes:\n",
        "        return pensoes[x]\n",
        "\n",
        "# Create a new column 'tipo_pensao_agrupado' by applying the function.\n",
        "df['tipo_pensao_agrupado'] = df['tipo_pensao'].apply(categorizando)\n",
        "\n",
        "# Select and reorder columns for the final DataFrame.\n",
        "df= df[['ano', 'mes', 'data_inicio_pensao', 'ano_inicio_pensao', 'decada_inicio_pensao', 'tipo_pensao','tipo_pensao_agrupado', 'total']]\n",
        "# Display the final DataFrame.\n",
        "df"
      ],
      "metadata": {
        "id": "qk50L84eVGLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "DWdiV255Duk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the bigquery library from google.cloud\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize the BigQuery client, specifying the Google Cloud project ID.\n",
        "# This client object is the main entry point for interacting with the BigQuery API.\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')\n",
        "\n",
        "# Create a reference to the BigQuery dataset named 'perfil_remuneracao'.\n",
        "# This object points to the dataset where the table will be created or updated.\n",
        "dataset_ref = client.dataset('perfil_remuneracao')\n",
        "\n",
        "# Define the schema for the destination BigQuery table.\n",
        "# The schema is a list of SchemaField objects, where each object defines a column's:\n",
        "# 1. Name (e.g., 'ano')\n",
        "# 2. Data type (e.g., 'INTEGER')\n",
        "# 3. Description (e.g., 'Ano de referência da observação')\n",
        "schema=[bigquery.SchemaField('ano','INTEGER',description='Ano de referência da observação'),\n",
        "        bigquery.SchemaField('mes','INTEGER',description='Mês de referência da observação'),\n",
        "        bigquery.SchemaField('data_inicio_pensao','DATETIME',description='Data de início da pensão'),\n",
        "        bigquery.SchemaField('ano_inicio_pensao','INTEGER',description='Ano de início da pensão extraido da data'),\n",
        "        bigquery.SchemaField('decada_inicio_pensao','INTEGER',description='Década de início da pensão'),\n",
        "        bigquery.SchemaField('tipo_pensao','STRING',description='Tipo de pensão'),\n",
        "        bigquery.SchemaField('tipo_pensao_agrupado','STRING',description='Categorização das pensões'),\n",
        "        bigquery.SchemaField('total','INTEGER',description='Quantidade total da observação')\n",
        "        ]\n",
        "\n",
        "# Create a reference to the target table within the dataset specified earlier.\n",
        "# The table will be named 'MILITARES_inicio_pensoes_total_v9'.\n",
        "table_ref = dataset_ref.table('MILITARES_inicio_pensoes_total_v9')\n",
        "\n",
        "# Configure the load job by creating a LoadJobConfig object.\n",
        "# Here, we specify the schema that BigQuery should use for the table. This ensures\n",
        "# that the columns in BigQuery have the correct data types and descriptions.\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Start the job to load data from the pandas DataFrame 'df' into the specified BigQuery table ('table_ref').\n",
        "# The job is configured with the previously defined 'job_config'. This command sends the data to BigQuery.\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the load job to complete and retrieve its result.\n",
        "# This line is blocking and will pause the script's execution until the data upload is finished.\n",
        "# It's crucial for ensuring the data is fully loaded before the script ends or proceeds.\n",
        "job.result()"
      ],
      "metadata": {
        "id": "pTdvtDsAVr4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}