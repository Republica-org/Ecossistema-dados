{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "i7fvn9xzmJZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J25FGzQHPQoZ",
        "outputId": "06e402aa-e60d-4d90-9990-c3abd7f6ec5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gcloud\n",
            "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/454.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from gcloud) (0.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.11/dist-packages (from gcloud) (1.70.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.11/dist-packages (from gcloud) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gcloud) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=2.0.1->gcloud) (4.9.1)\n",
            "Building wheels for collected packages: gcloud\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602927 sha256=2cb9ae7dcb2a200bf0a7ec9c40838bb59e5652d4abb1cbf3b5eb544afe25fddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/e8/d1/cb82a63f69083ea485de71d14248b8d145f1af46a41578be9c\n",
            "Successfully built gcloud\n",
            "Installing collected packages: gcloud\n",
            "Successfully installed gcloud-0.18.3\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=sv64kWk03wnnlOe8vusMbgnoqgKcch&prompt=consent&token_usage=remote&access_type=offline&code_challenge=7a_-lB5-a89r_dHs9UrULGLy3YCSmGqlcRskwDfobQ8&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVMBsJj6E_TofyPTjzQvrQ3gFI0eEXhSXk-_tuoPxFcyoIp8frym5ZhcffJt5U_1-NGljw\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "#Prepare credentials to upload table after treatment\n",
        "!pip install gcloud\n",
        "!gcloud auth application-default login\n",
        "\n",
        "#Basic dependecies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas_gbq\n",
        "from google.cloud import bigquery\n",
        "import glob\n",
        "import openpyxl\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento"
      ],
      "metadata": {
        "id": "iqIteeoVPkPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from an XML file and load it into a pandas DataFrame.\n",
        "# A DataFrame is a 2-dimensional labeled data structure.\n",
        "df = pd.read_xml('acoes_afirmativas.xml')\n",
        "\n",
        "# Rename specific columns of the DataFrame for better readability\n",
        "# and to follow a consistent naming convention (snake_case).\n",
        "# The 'inplace=True' argument modifies the DataFrame directly,\n",
        "# avoiding the need to create a new one.\n",
        "df.rename(columns={\n",
        "    \"tipoCota\": \"tipo_cota\",\n",
        "    \"pubAlvo\": \"pub_alvo\",\n",
        "    \"comissVer\": \"comiss_ver\"\n",
        "}, inplace=True)\n",
        "\n",
        "#Drop specific row\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Save the modified DataFrame to a CSV (Comma Separated Values) file.\n",
        "# 'index=False' prevents pandas from writing the DataFrame index as a column in the CSV.\n",
        "df.to_csv('FLACSO_acoes_afirmativas.csv', index=False)\n"
      ],
      "metadata": {
        "id": "itRpeZg299vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento 2"
      ],
      "metadata": {
        "id": "VlNanaHuRiR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from a CSV file into a pandas DataFrame\n",
        "# Parameters:\n",
        "#   encoding=\"utf8\" - ensures proper handling of special characters\n",
        "#   decimal=\",\" - uses comma as decimal separator for numeric values\n",
        "df = pd.read_csv('FLACSO_acoes_afirmativas.csv', encoding='utf8', decimal=\",\")\n",
        "\n",
        "# Remove unnecessary columns from the DataFrame\n",
        "# Parameters:\n",
        "#   ['id', 'marker_id'] - list of columns to drop\n",
        "#   axis=1 - indicates column-wise operation\n",
        "#   inplace=True - modifies the DataFrame directly\n",
        "df.drop(['id', 'marker_id'], axis=1, inplace=True)\n",
        "\n",
        "# Extract year information from description text and create new 'ano' column\n",
        "# Method:\n",
        "#   str.extract() with regex pattern to find dates and capture year component\n",
        "# Regex explanation:\n",
        "#   \\b(\\d{2}\\.\\d{2}\\.(\\d{4}))\\b matches DD.MM.YYYY format dates\n",
        "#   [1] selects the second capture group (the year part)\n",
        "df['ano'] = df['descricao'].str.extract(r'\\b(\\d{2}\\.\\d{2}\\.(\\d{4}))\\b')[1]\n",
        "\n",
        "# Export the processed data to a new CSV file for manual treatment\n",
        "# Parameters:\n",
        "#   index=False - prevents writing row numbers to the file\n",
        "df.to_csv('FLACSO_acoes_afirmativas_v1.csv', index=False)"
      ],
      "metadata": {
        "id": "7HfWmANhBODu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento 2.1"
      ],
      "metadata": {
        "id": "cLqRKOnIJGTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file with UTF-8 encoding and comma as decimal separator\n",
        "df = pd.read_csv('FLACSO_acoes_afirmativas_v2.csv', encoding='utf8', decimal=\",\")\n",
        "\n",
        "# Rename columns for better clarity and standardization\n",
        "df.rename(columns={\n",
        "    'descricao': 'legislacao',\n",
        "    'regiao': 'nome_regiao',\n",
        "    'estado': 'sigla_uf',\n",
        "    'identificacao': 'forma_identificacao',\n",
        "    'pub_alvo': 'nomenclatura_legislacao',\n",
        "    'Ano': 'ano',\n",
        "    'Legislação': 'legislacao',\n",
        "    'comissionado': 'flag_comissionado',\n",
        "    'comiss_ver': 'flag_comiss_verificacao',\n",
        "    'cidade': 'nome_municipio'\n",
        "}, inplace=True)\n",
        "\n",
        "# Reorder columns by creating a new column order\n",
        "temp_cols = df.columns.tolist()\n",
        "new_cols = temp_cols[4:5] + temp_cols[0:4] + temp_cols[5:]\n",
        "df = df[new_cols]\n",
        "\n",
        "# Standardize region names with proper capitalization\n",
        "df['nome_regiao'] = df['nome_regiao'].replace({\n",
        "    'sul': 'Sul',\n",
        "    'norte': 'Norte',\n",
        "    'nordeste': 'Nordeste',\n",
        "    'centro-oeste': 'Centro-oeste',\n",
        "    'sudeste': 'Sudeste'\n",
        "})\n",
        "\n",
        "# Standardize 'tipo_cota' values by consolidating similar entries\n",
        "df['tipo_cota'] = df['tipo_cota'].replace({\n",
        "    'Concurso público': 'Concurso público',\n",
        "    'concurso público': 'Concurso público',\n",
        "    'Concurso Público e estagiário': 'Concurso público e estágio profissional',\n",
        "    'Concurso público e contratação temporária.': 'Concurso público e contratação temporária',\n",
        "    'Sistema de pontuação diferenciado em concurso público': 'Concurso público'\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "AQ4brB1EB7cY",
        "outputId": "b909e2d0-0f75-45b8-f4a4-ac09874ce093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-221570175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FLACSO_acoes_afirmativas_v2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m df.rename(columns={'descricao':'legislacao', 'regiao':'nome_regiao', 'estado':'sigla_uf',\n\u001b[1;32m      3\u001b[0m \u001b[0;34m'identificacao'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'forma_identificacao'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pub_alvo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'nomenclatura_legislacao'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ano'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Legislação'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'legislacao'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comissionado'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'flag_comissionado'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m 'comiss_ver':'flag_comiss_verificacao','cidade':'nome_municipio' },inplace=True)\n\u001b[1;32m      5\u001b[0m \u001b[0mtemp_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload"
      ],
      "metadata": {
        "id": "POl0Z33IKwBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the BigQuery table\n",
        "# Each SchemaField specifies column name, type, and description\n",
        "schema = [\n",
        "    bigquery.SchemaField('ano', 'INTEGER', description='Ano de implementação da legislação.'),\n",
        "    bigquery.SchemaField('abrangencia', 'STRING', description='Se a abrangência é municipal, estadual, federal, nacional ou distrital.'),\n",
        "    bigquery.SchemaField('nome_regiao', 'STRING', description='Nome da Região.'),\n",
        "    bigquery.SchemaField('sigla_uf', 'STRING', description='Sigla da Unidade da Federação.'),\n",
        "    bigquery.SchemaField('nome_municipio', 'STRING', description='Município.'),\n",
        "    bigquery.SchemaField('legislacao', 'STRING', description='Número da legislação e detalhes.'),\n",
        "    bigquery.SchemaField('regulamentacao', 'STRING', description='Detalhes sobre a regulamentação'),\n",
        "    bigquery.SchemaField('tipo_cota', 'STRING', description='A cota vale para quais formas de ingresso.'),\n",
        "    bigquery.SchemaField('flag_comissionado', 'INTEGER', description='A ação abrange cargos comissionados?'),\n",
        "    bigquery.SchemaField('percentual', 'STRING', description='Percentual de vagas reservadas'),\n",
        "    bigquery.SchemaField('nomenclatura_legislacao', 'STRING', description='Se a abrangência é municipal, estadual ou federal'),\n",
        "    bigquery.SchemaField('forma_identificacao', 'STRING', description='Forma de identificação do público alvo na legislação.'),\n",
        "    bigquery.SchemaField('flag_comiss_verificacao', 'INTEGER', description='Se há comissão de verificação.'),\n",
        "    bigquery.SchemaField('vigencia', 'STRING', description='Se está vigente ou não.'),\n",
        "    bigquery.SchemaField('lat', 'STRING', description='Latitude'),\n",
        "    bigquery.SchemaField('lng', 'STRING', description='Longitude')\n",
        "]\n",
        "\n",
        "# Initialize BigQuery client and configure the upload\n",
        "client = bigquery.Client(project='repositoriodedadosgpsp')  # Connect to the specified project\n",
        "dataset_ref = client.dataset('acoes_afirmativas')  # Reference to the target dataset\n",
        "\n",
        "# Configure the table reference with standardized naming (FONTE_algo_intuitivo_dado)\n",
        "table_ref = dataset_ref.table('FLACSO_acoes_afirmativas_v1')\n",
        "\n",
        "# Set up the job configuration with our predefined schema\n",
        "job_config = bigquery.LoadJobConfig(schema=schema)\n",
        "\n",
        "# Execute the upload job from DataFrame to BigQuery\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "job.result()  # Wait for the job to complete"
      ],
      "metadata": {
        "id": "_JZ-RB9xsCkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}